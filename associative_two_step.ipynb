{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fit two step task with an associative algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "import patsy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import basinhopping\n",
    "from sklearn import linear_model\n",
    "import multiprocessing\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import beta\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = .45 #learning rate\n",
    "m=3.0 #temperature (not inverse)\n",
    "p=.4 #tendency to repeat actions >1 means perseveration (from Daw 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Helper RL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up data structures and initialize reward and transition probabilities\n",
    "def initialize():\n",
    "    #define relevant objects\n",
    "    objects = ['a1','a2','b1','b2','c1','c2']\n",
    "    states = ['a','b','c','terminal']\n",
    "    actions = ['1','2']\n",
    "\n",
    "    #initialize empty data structures\n",
    "    transitions = {s2: {a : {s1 : 0 for s1 in states} for a in actions} for s2 in states}\n",
    "    rewards = {s: {a : 0 for a in actions} for s in states}\n",
    "    associations = {o1: {o2 : 0 for o2 in objects if o1!=o2} for o1 in objects}\n",
    "    V = {key: 0 for key in objects}\n",
    "      \n",
    "    #fill in transition probabilities\n",
    "    for s in ['b','c']: #all actions lead to terminal state\n",
    "        for a in actions:\n",
    "            transitions[s][a]['terminal'] = 1\n",
    "    transitions['a']['1']['b'] = .7\n",
    "    transitions['a']['1']['c'] = .3\n",
    "    transitions['a']['2']['b'] = .3\n",
    "    transitions['a']['2']['c'] = .7\n",
    "\n",
    "    #set up reward probs\n",
    "    rewards['b']['1'] = .7\n",
    "    rewards['b']['2'] = .3\n",
    "    rewards['c']['1'] = .3\n",
    "    rewards['c']['2'] = .7\n",
    "    \n",
    "    return transitions, rewards, V, associations, objects, states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gradually shift reward probabilitites to encourage learning\n",
    "def update_rewards(rewards):\n",
    "    for s in ['b','c']: #only update end states\n",
    "        for a in actions:\n",
    "            shift = np.random.normal(0,.025)\n",
    "            if (rewards[s][a] + shift > .75) or (rewards[s][a] + shift < .25): #reflecting boundaries\n",
    "                rewards[s][a] = rewards[s][a] - shift\n",
    "            else:\n",
    "                rewards[s][a] = rewards[s][a] + shift\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#draw a reward according to reward probability functions\n",
    "def get_reward(state,action,rewards):\n",
    "    return scipy.stats.bernoulli.rvs(rewards[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get new state according to state, action, and transition probabilities\n",
    "def next_state(state,action): \n",
    "    probs = map(lambda x: transitions[state][action][x], states)\n",
    "    return np.random.choice(a=states,p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pick an action according to softmax\n",
    "def get_action(state,V,last_a_action):\n",
    "    Vs = map(lambda a: V[state+a],actions) #get values of each object in state\n",
    "    if state == 'a': #model perseveration\n",
    "        if last_a_action == '1':\n",
    "            Vs[0] = Vs[0] + p\n",
    "        else:\n",
    "            Vs[1] = Vs[1] + p\n",
    "    normalizing_constant = np.sum(map(lambda v: np.exp(m*v),Vs)) #get total value of state\n",
    "    probs = map(lambda v: np.exp(v*m), Vs)\n",
    "    probs = probs / normalizing_constant\n",
    "    return np.random.choice(a=actions,p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#every time a transition occurs, increment the association between those two objects\n",
    "def update_associations(state,new_state,action,associations, nsteps):\n",
    "    if new_state != 'terminal':\n",
    "        nsteps +=1\n",
    "        for a in actions:\n",
    "            associations[state + action][new_state + a] = associations[state + action][new_state + a] + 1\n",
    "            associations[new_state + a][state + action] = associations[state + action][new_state + a] #make symmetric\n",
    "    return associations, nsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_value(rew,state,new_state,action,V,associations,nsteps):\n",
    "#Not sure whether to have value updated between first and second-stage choices. Doesn't seem to influence results one way or another\n",
    "#     if new_state != 'terminal':\n",
    "#         delta = rew + max(V[new_state + actions[0]],V[new_state + actions[1]]) - V[state+action]\n",
    "#     else:\n",
    "#         delta = rew - V[state+action]\n",
    "    delta = rew - V[state+action]\n",
    "    V[state+action] = V[state+action] + alpha*delta\n",
    "    \n",
    "    #percolate value one step back, weighted by the strength of association\n",
    "    for o in associations[state+action]:\n",
    "        delta = rew - V[o]\n",
    "        V[o] = V[o] + associations[state+action][o] * alpha* delta *4/ nsteps #4/nsteps is to normalize \n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Runs through the MDP until terminal state, keeping track of the output\n",
    "def take_step(state,rewards,associations,V,nsteps,output,last_a_action):\n",
    "    if state == 'terminal': #end state\n",
    "        rewards = update_rewards(rewards)\n",
    "        return rewards, associations, V, nsteps \n",
    "\n",
    "    #do standard MDP stuff\n",
    "    action = get_action(state,V,last_a_action)\n",
    "    new_state = next_state(state,action)\n",
    "    rew = get_reward(state,action,rewards)\n",
    "    if state == 'a':\n",
    "        last_a_action = action\n",
    "        \n",
    "    #log what's happening\n",
    "    output['rew'].append(rew)\n",
    "    output['action'].append(action)\n",
    "    output['newstate'].append(new_state)\n",
    "    output['state'].append(state)\n",
    "    \n",
    "    #update values and associations\n",
    "    associations,nsteps = update_associations(state,new_state,action,associations,nsteps) #update associations\n",
    "    value = update_value(rew,state,new_state,action,V,associations,nsteps)\n",
    "    \n",
    "    return take_step(new_state,rewards,associations,V,nsteps,output,last_a_action) #recurse until terminal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Main simulation code\n",
    "ntrials = 5000\n",
    "transitions, rewards, V, associations, objects, states, actions = initialize()\n",
    "nsteps = 0.0\n",
    "last_a_action = '1' #need one to get started\n",
    "output = {'state':[],'action':[],'newstate':[],'rew':[]}\n",
    "for i in range(ntrials):\n",
    "    rewards, associations, V, nsteps = take_step('a',rewards,associations,V,nsteps,output,last_a_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analyze output by transition type and stay/shift behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#analyze wherer transition was common or rare\n",
    "output['transition_type'] = []\n",
    "for n,s in enumerate(output['newstate']):\n",
    "    if s  == 'terminal':\n",
    "        output['transition_type'].append('end')\n",
    "    elif (s == 'b' and output['action'][n] == '1') or (s == 'c' and output['action'][n] == '2'):\n",
    "        output['transition_type'].append('common')\n",
    "    elif (s == 'b' and output['action'][n] == '2') or (s == 'c' and output['action'][n] == '1'):\n",
    "        output['transition_type'].append('rare')\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate whether a first level action was stay or switch stay and switch\n",
    "output['stay'] = np.nan\n",
    "a_indices =  output[output['state'] == 'a'].index\n",
    "a_indices = a_indices.values\n",
    "stay_or_switch = ['np.nan']\n",
    "for n,idx in enumerate(a_indices):\n",
    "    if n>0:\n",
    "        last_action = output.iloc[a_indices[n-1]].action\n",
    "        current_action = output.iloc[a_indices[n]].action\n",
    "        if last_action == current_action:\n",
    "            stay_or_switch.append('stay')\n",
    "        else:\n",
    "            stay_or_switch.append('switch')\n",
    "output.ix[output['state'] == 'a','stay']  = stay_or_switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10f41cb10>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAERCAYAAABy/XBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b7e4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parse (and plot) results\n",
    "out = {'transitions' : [], 'choices' :[], 'value' : []}\n",
    "for r in ['rewarded','nonrewarded']:\n",
    "    if r == 'rewarded':\n",
    "        rew = 1\n",
    "    else:\n",
    "        rew = 0\n",
    "        \n",
    "    indices = output[(output['newstate']=='terminal') & (output['rew'] == rew)].index[:-1] #indices of terminal state\n",
    "    transition_type = output.iloc[indices-1]['transition_type'].values #common or rare\n",
    "    action = output.iloc[indices+1]['stay'].values #stay or switch\n",
    "    \n",
    "    for c in ['common','rare']:\n",
    "        choices = list(action[transition_type == c])        \n",
    "        out['transitions'].append(c)\n",
    "        out['choices'].append(r)\n",
    "        out['value'].append(choices.count('stay')/float(len(choices)))\n",
    "\n",
    "out = pd.DataFrame(out)      \n",
    "sns.barplot(x='choices',y='value',hue='transitions',data=out,palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loook at associations and values learning\n",
    "for o1 in associations:\n",
    "    for o2 in associations:\n",
    "        if o1 != o2:\n",
    "            print o1,o2,associations[o1][o2]/nsteps\n",
    "print V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
