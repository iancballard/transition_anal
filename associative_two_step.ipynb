{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fit two step task with an associative algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "import patsy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import basinhopping\n",
    "from sklearn import linear_model\n",
    "import multiprocessing\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import beta\n",
    "##Code for analysis of fMRI experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrials = 200\n",
    "alpha = .2\n",
    "\n",
    "#initialize data structures\n",
    "objects = ['a1','a2','b1','b2','c1','c2']\n",
    "states = ['a','b','c','terminal']\n",
    "actions = ['1','2']\n",
    "\n",
    "#Initialize transition, rewards, values matrics\n",
    "transitions = {}\n",
    "rewards = {}\n",
    "V = {}\n",
    "associations = {}\n",
    "for s in states:\n",
    "    transitions[s] = {}\n",
    "    rewards[s] = {}\n",
    "    for a in actions:\n",
    "        transitions[s][a] = {}\n",
    "        rewards[s][a] = 0\n",
    "for o in objects:\n",
    "    V[o] = 0\n",
    "    associations[o] = {}\n",
    "\n",
    "for o1 in associations:\n",
    "    for o2 in objects:\n",
    "        if o1 != o2: #avoid self associations\n",
    "            associations[o1][o2] = 0\n",
    "\n",
    "#fill in transition probs\n",
    "for s1 in states:\n",
    "    for a in actions:\n",
    "        for s2 in states:\n",
    "            transitions[s1][a][s2] = 0         \n",
    "transitions['b']['1']['terminal'] = 1\n",
    "transitions['b']['2']['terminal'] = 1\n",
    "transitions['c']['1']['terminal'] = 1\n",
    "transitions['c']['2']['terminal'] = 1\n",
    "transitions['a']['1']['b'] = .7\n",
    "transitions['a']['1']['c'] = .3\n",
    "transitions['a']['2']['b'] = .3\n",
    "transitions['a']['2']['c'] = .7\n",
    "\n",
    "#set up reward probs\n",
    "rewards['b']['1'] = .6\n",
    "rewards['b']['2'] = .4\n",
    "rewards['c']['1'] = .4\n",
    "rewards['c']['2'] = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gradually shift reward probabilitites to encourage learning\n",
    "def update_rewards(rewards):\n",
    "    for s in ['b','c']: #only update end states\n",
    "        for a in actions:\n",
    "            shift = np.random.normal(0,.025)\n",
    "            if (rewards[s][a] + shift > .75) or (rewards[s][a] + shift < .25): #reflecting boundaries\n",
    "                rewards[s][a] = rewards[s][a] - shift\n",
    "            else:\n",
    "                rewards[s][a] = rewards[s][a] + shift\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_reward(state,action,rewards):\n",
    "    return scipy.stats.bernoulli.rvs(rewards[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_state(state,action):\n",
    "    probs = map(lambda x: transitions[state][action][x], states)\n",
    "    return np.random.choice(a=states,p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action(state):\n",
    "    return actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_associations(state,new_state,action,associations):\n",
    "    if new_state != 'terminal':\n",
    "        for a in actions:\n",
    "            associations[state + action][new_state + a] = associations[state + action][new_state + a] + 1\n",
    "            associations[new_state + a][state + action] = associations[state + action][new_state + a] #make symmetric\n",
    "    \n",
    "    #normalize associations\n",
    "    total_strength = 0\n",
    "    for o1 in objects:\n",
    "        for o2 in objects:\n",
    "            if o1 != o2:\n",
    "                total_strength += associations[o1][o2]\n",
    "    for o1 in objects:\n",
    "        for o2 in objects:\n",
    "            if o1 != o2:\n",
    "                associations[o1][o2] = associations[o1][o2] / (total_strength*1.0)\n",
    "    return associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_value(rew,state,action,V,associations):\n",
    "    delta = rew - V[state+action]\n",
    "    V[state+action] += alpha*delta\n",
    "    \n",
    "    #percolate value one step back, weighted by the strength of association\n",
    "    for o in associations[state+action]:\n",
    "        delta = rew - V[o]\n",
    "        V[o] = V[o] + associations[state+action][o] * alpha* delta\n",
    "    \n",
    "    for o1 in associations[state+action]:\n",
    "        for o2 in associations[o1]:\n",
    "            if o1 != o2:\n",
    "                delta = rew - V[o2]\n",
    "                V[o2] = V[o2] + associations[state+action][o] * associations[o1][o2]* alpha* delta\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a1': 0.09482371585115376,\n",
       " 'a2': 0.0,\n",
       " 'b1': 0.3664965207688938,\n",
       " 'b2': 0.0,\n",
       " 'c1': 0.31561346899170006,\n",
       " 'c2': 0.0}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run trial\n",
    "def take_step(state,rewards,associations):\n",
    "    if state == 'terminal': #end state\n",
    "        rewards = update_rewards(rewards)\n",
    "        return rewards\n",
    "    \n",
    "    #do standard MDP stuff\n",
    "    action = get_action(state)\n",
    "    new_state = next_state(state,action)\n",
    "    rew = get_reward(state,action,rewards)\n",
    "\n",
    "    #update values and associations\n",
    "    associations = update_associations(state,new_state,action,associations) #update associations\n",
    "    value = update_value(rew,state,action,V,associations)\n",
    "    \n",
    "    take_step(new_state,rewards,associations)\n",
    "    \n",
    "    return V\n",
    "take_step('a',rewards,associations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
